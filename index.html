
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<script type="text/javascript" charset="utf-8" src="https://ajax.googleapis.com/ajax/libs/jquery/1.3.2/jquery.min.js"></script> 
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

<style type="text/css">
body {
    font-family: "Titillium Web", "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
    font-weight: 300;
    font-size: 17px;
    margin-left: auto;
    margin-right: auto;
}

@media screen and (min-width: 980px){
    body {
        width: 980px;
    }
}

h1 {
    font-weight:300;
    line-height: 1.15em;
}

h2 {
    font-size: 1.75em;
}
a:link,a:visited {
    color: #5364cc;
    text-decoration: none;
}
a:hover {
    color: #208799;
}
h1 {
    text-align: center;
}
h2,h3 {
    text-align: left;
}

h1 {
    font-size: 40px;
    font-weight: 500;
}
h2 {
    font-weight: 400;
    margin: 16px 0px 4px 0px;
}
h3 {
    font-weight: 600;
    margin: 16px 0px 4px 0px;
}

.paper-title {
    padding: 1px 0px 1px 0px;
}
section {
    margin: 32px 0px 32px 0px;
    text-align: justify;
    clear: both;
}
.col-5 {
     width: 20%;
     float: left;
}
.col-4 {
     width: 25%;
     float: left;
}
.col-3 {
     width: 33%;
     float: left;
}
.col-2 {
     width: 50%;
     float: left;
}
.col-1 {
     width: 100%;
     float: left;
}

.author-row, .affil-row {
    font-size: 26px;
}

.author-row-new { 
    text-align: center; 
}

.author-row-new a {
    display: inline-block;
    font-size: 20px;
    padding: 4px;
}

.author-row-new sup {
    color: #313436;
    font-size: 12px;
}

.affiliations-new {
    font-size: 18px;
    text-align: center;
    width: 80%;
    margin: 0 auto;
    margin-bottom: 20px;
}

.row {
    margin: 16px 0px 16px 0px;
}
.authors {
    font-size: 26px;
}
.affiliatons {
    font-size: 18px;
}
.affil-row {
    margin-top: 18px;
}
.teaser {
    max-width: 100%;
}
.text-center {
    text-align: center;  
}
.screenshot {
    width: 256px;
    border: 1px solid #ddd;
}
.screenshot-el {
    margin-bottom: 16px;
}
hr {
    height: 1px;
    border: 0; 
    border-top: 1px solid #ddd;
    margin: 0;
}
.material-icons {
    vertical-align: -6px;
}
p {
    line-height: 1.25em;
}
.caption {
    font-size: 16px;
    color: #666;
    margin-top: 4px;
    margin-bottom: 10px;
}
video {
    display: block;
    margin: auto;
}
figure {
    display: block;
    margin: auto;
    margin-top: 10px;
    margin-bottom: 10px;
}
#bibtex pre {
    font-size: 14px;
    background-color: #eee;
    padding: 16px;
}
.blue {
    color: #2c82c9;
    font-weight: bold;
}
.orange {
    color: #d35400;
    font-weight: bold;
}
.flex-row {
    display: flex;
    flex-flow: row wrap;
    padding: 0;
    margin: 0;
    list-style: none;
}

.paper-btn-coming-soon {
    position: relative; 
    top: 0;
    left: 0;
}

.coming-soon {
    position: absolute;
    top: -15px;
    right: -15px;
}

.paper-btn {
  position: relative;
  text-align: center;

  display: inline-block;
  margin: 8px;
  padding: 8px 8px;

  border-width: 0;
  outline: none;
  border-radius: 2px;
  
  background-color: #5364cc;
  color: white !important;
  font-size: 20px;
  width: 100px;
  font-weight: 600;
}
.paper-btn-parent {
    display: flex;
    justify-content: center;
    margin: 16px 0px;
}

.paper-btn:hover {
    opacity: 0.85;
}

.container {
    margin-left: auto;
    margin-right: auto;
    padding-left: 16px;
    padding-right: 16px;
}

.venue {
    font-size: 23px;
}

.topnav {
    background-color: #EEEEEE;
    overflow: hidden;
}

.topnav div {
    max-width: 1070px;
    margin: 0 auto;
}

.topnav a {
    display: inline-block;
    color: black;
    text-align: center;
    vertical-align: middle;
    padding: 16px 16px;
    text-decoration: none;
    font-size: 18px;
}

.topnav img {
    padding: 2px 0px;
    width: 100%;
    margin: 0.2em 0px 0.3em 0px;
    vertical-align: middle;
}

pre {
    font-size: 0.9em;
    padding-left: 7px;
    padding-right: 7px;
    padding-top: 3px;
    padding-bottom: 3px;
    border-radius: 3px;
    background-color: rgb(235, 235, 235);
    overflow-x: auto;
}

.download-thumb {
    display: flex;
}

@media only screen and (max-width: 620px) {
    .download-thumb {
        display: none;
    }
}

.paper-stuff {
    width: 50%;
    font-size: 20px;
}

@media only screen and (max-width: 620px) {
    .paper-stuff {
        width: 100%;
    }
}
* {
  box-sizing: border-box;
}

.column {
  text-align: center;
  float: left;
  width: 16.666%;
  padding: 5px;
}
.column3 {
  text-align: center;
  float: left;
  width: 33.333%;
  padding: 5px;
}
.border-right {
    border-right: 1px solid black;
}
.border-bottom{
    border-bottom: 1px solid black;
}


/* Clearfix (clear floats) */
.row::after {
  content: "";
  clear: both;
  display: table;
}

/* Responsive layout - makes the three columns stack on top of each other instead of next to each other */
@media screen and (max-width: 500px) {
  .column {
    width: 100%;
  }
}
@media screen and (max-width: 500px) {
  .column3 {
    width: 100%;
  }
}

</style>

<script type="text/javascript" src="../js/hidebib.js"></script>
    <link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'>
    <head>
        <title> LOSS-SLAM: Lightweight Open-Set Semantic <br>
            Simultaneous Localization and Mapping</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta property="og:description" content="LOSS SLAM: Lightweight Open-Set Semantic <br>
        Simultaneous Localization and Mapping"/>
        <link href="https://fonts.googleapis.com/css2?family=Material+Icons" rel="stylesheet">
    </head>

 <body>
<div class="topnav" id="myTopnav">
    <div>
        <a href="https://marinerobotics.mit.edu/" ><strong>MIT Marine Robotics Group</strong></a>
    </div>
</div>
<div class="container">
    <div class="paper-title">
    <h1> 
        <font color="#5364cc">LOSS-SLAM</font>: 
        <font color="#5364cc">L</font>ightweight <font color="#5364cc">O</font>pen-<font color="#5364cc">S</font>et <font color="#5364cc">S</font>emantic <br>
        <font color="#5364cc">S</font>imultaneous <font color="#5364cc">L</font>ocalization <font color="#5364cc">a</font>nd <font color="#5364cc">M</font>apping</h1>
    </div>

    <div id="authors">
        <center>
            <div class="author-row-new">
                <a href="https://www.linkedin.com/in/kurran-singh/">Kurran Singh</a>,
                <a href="https://www.linkedin.com/in/timmagoun">Tim Magoun</a>,
                <a href="https://www.csail.mit.edu/person/john-leonard">John Leonard</a>
            </div>
        </center>
        <center>
            <div class="affiliations">
                <span>MIT CSAIL</span><br/>
                {singhk,magoun,jleonard}@mit.edu
            </div>
        </center>

        <div style="clear: both">
            <div class="paper-btn-parent">
            <a class="paper-btn" href="https://arxiv.org/abs/2210.06978">
                <span class="material-icons"> description </span> 
                 Paper
            </a>
            <div class="paper-btn-coming-soon">
                <a class="paper-btn" href="https://github.com/kurransingh/loss-slam">
                    <span class="material-icons"> code </span>
                    Code
                </a>
            </div>
            <div class="paper-btn-coming-soon">
                <a class="paper-btn" href="https://www.dropbox.com/sh/vqdwafwwjwmybgg/AADJRTwnxJWpcGi_aVCPVfgka?dl=0">
                    <span class="material-icons"> folder </span>
                    Data
                </a>
            </div>
        </div></div>
    </div>
    <!-- <style>
        #teaser-image {
            display: flex;
            justify-content: center;
        }

        #teaser-image .video-container {
            max-width: 100%; /* Set maximum width to 100% of the viewport */
            margin: 10 10px; /* Adjust margin as needed */
            width: 1600%; /* Set width to 25% to fit three videos side by side */
        }

        #teaser-image .video-background {
            width: 100%;
        }
    </style>
    <section id="teaser-image">
        <figure class="video-container">
            <video class="left" autoplay loop muted playsinline class="video-background">
                <source src="assets/loss_slam_closed_clipped.mp4" type="video/mp4">
                Your browser does not support the video tag.
            </video>
        </figure>
        <figure class="video-container">
            <video class="center" autoplay loop muted playsinline class="video-background">
                <source src="assets/geometric_clipped.mp4" type="video/mp4">
                Your browser does not support the video tag.
            </video>
        </figure>
        <figure class="video-container">
            <video class="right" autoplay loop muted playsinline class="video-background">
                <source src="assets/open_set_trimmed.mp4" type="video/mp4">
                Your browser does not support the video tag.
            </video>
        </figure>
    </section> -->
    <style>
        .video-container {
          width: 100%; /* Each video takes up 1/3 of the container width */
          float: left; /* Float videos left to display them horizontally */
          box-sizing: border-box; /* Include padding and border in the element's total width and height */
          padding: 10px; /* Add padding around each video */
        }
      
        video {
          width: 100%; /* Make sure the video takes up 100% of its container width */
          height: auto; /* Automatically adjust height based on width to maintain aspect ratio */
        }
      </style>

      <!-- <div class="video-container">
        <video autoplay loop muted>
          <source src="assets/loss_slam_closed_clipped.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>
      
      <div class="video-container">
        <video autoplay loop muted>
          <source src="assets/geometric_clipped.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>
       -->
      <div class="video-container">
        <video autoplay loop muted>
          <source src="assets/open_set_trimmed.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>
      

    <section id="news">
        <hr>
        <h2>News</h2>
        <div class="row">
            <div><span class="material-icons"> event </span> [February 2024] <a href="https://kurransingh.github.io/open-set-slam/">Project page</a> released!</div>
            <div><span class="material-icons"> event </span> [February 2024] <a href="https://www.dropbox.com/sh/vqdwafwwjwmybgg/AADJRTwnxJWpcGi_aVCPVfgka?dl=0">Data</a> released!</div>

        </div>
    </section>
    <section id="abstract"/>
        <hr>
        <h2>Abstract</h2>
        <div class="flex-row">
            <p>
                Enabling robots to understand the world in terms
                of objects is a critical building block towards higher level
                autonomy. The success of foundation models in vision has
                created the ability to segment and identify nearly all objects
                in the world. However, utilizing such objects to localize the
                robot and build an open-set semantic map of the world remains
                an open research question. In this work, a system of identi-
                fying, localizing, and encoding objects is tightly coupled with
                probabilistic graphical models for performing open-set semantic
                simultaneous localization and mapping (SLAM). Results are
                presented demonstrating that the proposed lightweight object
                encoding can be used to perform more accurate object-based
                SLAM than existing open-set methods, closed-set methods,
                and geometric methods while incurring smaller computational
                overhead than existing open-set mapping methods.
            </p>
        </div>
        <br>

    <center>
        <iframe width="840" height="472.5" src="https://www.youtube.com/embed/cap-QvtrYF8?si=m5Gsddmk23s6zqbA" title="YouTube video player"
                frameborder="0"
                allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
                allowfullscreen></iframe>
    </center>
    <br>
    </section>
    <section id="method"/>
        <hr>
        <h2>Method</h2>
        <center>
            <figure style="width: 100%;">
                    <a>
                        <img width="80%" src="assets/icra24_sys_diagram.png"> 
                    </a>
                    <p class="caption" style="margin-bottom: 24px;"><br>
                        An overview of the proposed open-set data association system
                        coupled with a factor graph framework when a new image and odometry
                        pair is received. The image is fed into the DINO network to get patch-
                        level encodings, which are then clustered into objects. Those clusters are
                        determined to be either foreground or background based on the attention
                        heads. A connected component analysis yields instance level segmentations,
                        from which for each object, a single encoding vector is used as the object
                        representation. The encoding is compared against the existing landmarks’
                        encodings to determine class matches. The pose of the object is also
                        compared against the existing objects’ poses as the final data association
                        filter (not pictured). After building a factor with all matches that pass the
                        filter (depending on backend method, either expectation-maximization, max-
                        mixtures, or max-likelihood factor), we add a new pose (light blue) to the
                        factor graph with a factor connecting it (light pink) to the previous landmark.
                    </p>
            </figure>

    </section>
    <section id="paper">
        <h2>Paper</h2>
        <hr>
        <div class="flex-row">
            <div class="download-thumb">
            <div style="box-sizing: border-box; padding: 16px; margin: auto;">
                <a href="https://kurransingh.github.io/open-set-slam/"><img class="screenshot" src="assets/title_page_pic.png"></a>
            </div>
        </div>
            <div class="paper-stuff">
                <p><b>LOSS-SLAM: Lightweight Open-Set Semantic Simultaneous Localization and Mapping</b></p>
                <p>Kurran Singh, Tim Magoun, John Leonard</p>
                <!-- <p><i>Advances in Neural Information Processing Systems (NeurIPS), 2022 <b></b></i></p>  -->
                <div><span class="material-icons"> description </span><a href=""> arXiv version</a></div>
                <div><span class="material-icons"> insert_comment </span><a href="assets/singh2024opensetslam.bib"> BibTeX</a></div>
                <div><span class="material-icons"> integration_instructions </span><a href="https://github.com/kurransingh/loss-slam"> Code</a></div>
            </div>
            </div>
        </div>
    </section>

    <section id="bibtex">
        <h2>Citation</h2>
        <hr>
        <pre><code>@inproceedings{singh2024opensetslam,
    title=LOSS-SLAM: Lightweight Open-Set Semantic Simultaneous Localization and Mapping,
    author={Kurran Singh and Tim Magoun and John Leonard},
    booktitle={arxiv Preprint},
    year={2024}
}</code></pre>
    </section>


    <section>
        This webpage template was recycled from <a href='https://nv-tlabs.github.io/LION/'>here</a>.
    </section>
</div>
</body>
</html>
